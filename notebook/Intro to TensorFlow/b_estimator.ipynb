{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2b. Machine Learning using tf.estimator </h1>\n",
    "\n",
    "In this notebook, we will create a machine learning model using tf.estimator and evaluate its performance.  The dataset is rather small (7700 samples), so we can do it all in-memory.  We will also simply pass the raw data in as-is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data created in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'str'>\n",
      "fare_amount\n",
      "fare_amount    float64\n",
      "pickuplon      float64\n",
      "pickuplat      float64\n",
      "dropofflon     float64\n",
      "dropofflat     float64\n",
      "passengers       int64\n",
      "key              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# In CSV, label is the first column, after the features, followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "print(type(CSV_COLUMNS)) # list\n",
    "print(type(FEATURES)) # list, from pickuplon to key\n",
    "print(type(LABEL)) #string, fare_amount\n",
    "print(LABEL) #fare_amount\n",
    "\n",
    "df_train = pd.read_csv('./taxi-train.csv', header = None, names = CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('./taxi-valid.csv', header = None, names = CSV_COLUMNS)\n",
    "df_test = pd.read_csv('./taxi-test.csv', header = None, names = CSV_COLUMNS)\n",
    "\n",
    "print(df_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Train and eval input functions to read from Pandas Dataframe </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an appropriate input_fn to read the training data\n",
    "def make_train_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    #ADD CODE HERE\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create an appropriate input_fn to read the validation data\n",
    "def make_eval_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    #ADD CODE HERE\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    shuffle = True\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input function for predictions is the same except we don't provide a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create an appropriate prediction_input_fn\n",
    "def make_prediction_input_fn(df):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    #ADD CODE HERE\n",
    "    x = df\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature columns for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create feature columns\n",
    "#feature_columns = {'fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key'}\n",
    "\n",
    "\"\"\"\n",
    "feature_columns = [\n",
    "  tf.feature_column.numeric_column(\"pickuplon\"),\n",
    "  tf.feature_column.numeric_column(\"pickuplat\"),\n",
    "  tf.feature_column.numeric_column(\"dropofflon\"),\n",
    "  tf.feature_column.numeric_column(\"dropofflat\"),\n",
    "  tf.feature_column.numeric_column(\"passengers\"),\n",
    "  tf.feature_column.numeric_column(\"key\")]\n",
    "\"\"\"\n",
    "\n",
    "features_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_num_worker_replicas': 1, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f05a44af550>, '_tf_random_seed': None, '_task_id': 0, '_is_chief': True, '_global_id_in_cluster': 0, '_master': '', '_model_dir': 'taxi_trained', '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_session_config': None, '_keep_checkpoint_max': 5, '_service': None, '_train_distribute': None, '_save_checkpoints_secs': 600}\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 20530.875\n",
      "INFO:tensorflow:global_step/sec: 285.666\n",
      "INFO:tensorflow:step = 101, loss = 10432.828 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.119\n",
      "INFO:tensorflow:step = 201, loss = 11938.369 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.071\n",
      "INFO:tensorflow:step = 301, loss = 7627.741 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.595\n",
      "INFO:tensorflow:step = 401, loss = 5622.5664 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.353\n",
      "INFO:tensorflow:step = 501, loss = 19800.146 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.322\n",
      "INFO:tensorflow:step = 601, loss = 11833.966 (0.381 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 608 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.070661.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f05a4c44ac8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "# TODO: Train a linear regression model\n",
    "model = tf.estimator.LinearRegressor(feature_columns, OUTDIR)\n",
    "\n",
    "print(type(df_train))\n",
    "\n",
    "model.train(make_train_input_fn(df_train, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the validation data (we should defer using the test data to after we have selected a final model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-21-15:39:40\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-21-15:39:40\n",
      "INFO:tensorflow:Saving dict for global step 608: average_loss = 109.50922, global_step = 608, loss = 13023.774\n",
      "RMSE on dataset = 10.464665412902832\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, df):\n",
    "  metrics = model.evaluate(input_fn = make_eval_input_fn(df))# dfには、df_validが渡されている\n",
    "  print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))\n",
    "  \n",
    "print_rmse(model, df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nowhere near our benchmark (RMSE of $6 or so on this data), but it serves to demonstrate what TensorFlow code looks like.  Let's use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_num_worker_replicas': 1, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f05a4d8e198>, '_tf_random_seed': None, '_task_id': 0, '_is_chief': True, '_global_id_in_cluster': 0, '_master': '', '_model_dir': 'taxi_trained', '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_session_config': None, '_keep_checkpoint_max': 5, '_service': None, '_train_distribute': None, '_save_checkpoints_secs': 600}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[10.795773, 10.951951, 10.844597, 10.781398, 10.793583]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Predict from the estimator model we trained using test dataset\n",
    "# 要は、googleの方でtrain済みのmodelをここで読み込むらしい\n",
    "\n",
    "import itertools\n",
    "model = tf.estimator.LinearRegressor(feature_columns, OUTDIR)\n",
    "preds_iter = model.predict(make_eval_input_fn(df_valid))\n",
    "print([pred[\"predictions\"][0] for pred in list(itertools.islice(preds_iter, 5))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains why the RMSE was so high -- the model essentially predicts the same amount for every trip.  Would a more complex model help? Let's try using a deep neural network.  The code to do this is quite straightforward as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpg8psl4vb\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_num_worker_replicas': 1, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f05c6566cf8>, '_tf_random_seed': None, '_task_id': 0, '_is_chief': True, '_global_id_in_cluster': 0, '_master': '', '_model_dir': '/tmp/tmpg8psl4vb', '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_session_config': None, '_keep_checkpoint_max': 5, '_service': None, '_train_distribute': None, '_save_checkpoints_secs': 600}\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpg8psl4vb/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 41233320.0\n",
      "INFO:tensorflow:global_step/sec: 182.156\n",
      "INFO:tensorflow:step = 101, loss = 28133.121 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.691\n",
      "INFO:tensorflow:step = 201, loss = 17866.266 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.893\n",
      "INFO:tensorflow:step = 301, loss = 27467.102 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.075\n",
      "INFO:tensorflow:step = 401, loss = 17785.584 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.84\n",
      "INFO:tensorflow:step = 501, loss = 9343.656 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.068\n",
      "INFO:tensorflow:step = 601, loss = 7390.4336 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.715\n",
      "INFO:tensorflow:step = 701, loss = 12392.766 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.136\n",
      "INFO:tensorflow:step = 801, loss = 5009.523 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.093\n",
      "INFO:tensorflow:step = 901, loss = 8525.455 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.245\n",
      "INFO:tensorflow:step = 1001, loss = 8207.46 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.114\n",
      "INFO:tensorflow:step = 1101, loss = 9370.298 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.371\n",
      "INFO:tensorflow:step = 1201, loss = 7412.922 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.503\n",
      "INFO:tensorflow:step = 1301, loss = 14352.4375 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.847\n",
      "INFO:tensorflow:step = 1401, loss = 13442.297 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.844\n",
      "INFO:tensorflow:step = 1501, loss = 10347.842 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.178\n",
      "INFO:tensorflow:step = 1601, loss = 8834.451 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.14\n",
      "INFO:tensorflow:step = 1701, loss = 6303.2383 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.852\n",
      "INFO:tensorflow:step = 1801, loss = 7475.763 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.221\n",
      "INFO:tensorflow:step = 1901, loss = 13714.141 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.83\n",
      "INFO:tensorflow:step = 2001, loss = 6833.6826 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.937\n",
      "INFO:tensorflow:step = 2101, loss = 12440.773 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.925\n",
      "INFO:tensorflow:step = 2201, loss = 10477.98 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.889\n",
      "INFO:tensorflow:step = 2301, loss = 14265.835 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.003\n",
      "INFO:tensorflow:step = 2401, loss = 9562.179 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.607\n",
      "INFO:tensorflow:step = 2501, loss = 10559.096 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.527\n",
      "INFO:tensorflow:step = 2601, loss = 11622.832 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.934\n",
      "INFO:tensorflow:step = 2701, loss = 13020.652 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.97\n",
      "INFO:tensorflow:step = 2801, loss = 12896.839 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.599\n",
      "INFO:tensorflow:step = 2901, loss = 9731.973 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.365\n",
      "INFO:tensorflow:step = 3001, loss = 7316.291 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.315\n",
      "INFO:tensorflow:step = 3101, loss = 9319.508 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.337\n",
      "INFO:tensorflow:step = 3201, loss = 6646.14 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.881\n",
      "INFO:tensorflow:step = 3301, loss = 15037.451 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.053\n",
      "INFO:tensorflow:step = 3401, loss = 7224.9473 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.68\n",
      "INFO:tensorflow:step = 3501, loss = 6097.8213 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.487\n",
      "INFO:tensorflow:step = 3601, loss = 6471.24 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.134\n",
      "INFO:tensorflow:step = 3701, loss = 12224.834 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.135\n",
      "INFO:tensorflow:step = 3801, loss = 6577.9517 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.891\n",
      "INFO:tensorflow:step = 3901, loss = 11513.6875 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.883\n",
      "INFO:tensorflow:step = 4001, loss = 6466.1855 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.5\n",
      "INFO:tensorflow:step = 4101, loss = 11355.508 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.715\n",
      "INFO:tensorflow:step = 4201, loss = 8952.389 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.976\n",
      "INFO:tensorflow:step = 4301, loss = 7001.732 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.145\n",
      "INFO:tensorflow:step = 4401, loss = 15389.09 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.86\n",
      "INFO:tensorflow:step = 4501, loss = 15471.902 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.442\n",
      "INFO:tensorflow:step = 4601, loss = 12495.574 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.341\n",
      "INFO:tensorflow:step = 4701, loss = 15123.967 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.831\n",
      "INFO:tensorflow:step = 4801, loss = 6951.1616 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.836\n",
      "INFO:tensorflow:step = 4901, loss = 10994.217 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.75\n",
      "INFO:tensorflow:step = 5001, loss = 6541.511 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.139\n",
      "INFO:tensorflow:step = 5101, loss = 7261.943 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.571\n",
      "INFO:tensorflow:step = 5201, loss = 10889.65 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.364\n",
      "INFO:tensorflow:step = 5301, loss = 6086.0796 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.875\n",
      "INFO:tensorflow:step = 5401, loss = 13315.449 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.584\n",
      "INFO:tensorflow:step = 5501, loss = 8790.242 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.123\n",
      "INFO:tensorflow:step = 5601, loss = 8998.205 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.719\n",
      "INFO:tensorflow:step = 5701, loss = 10929.879 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.433\n",
      "INFO:tensorflow:step = 5801, loss = 6577.681 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.944\n",
      "INFO:tensorflow:step = 5901, loss = 6843.466 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.912\n",
      "INFO:tensorflow:step = 6001, loss = 12639.023 (0.334 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6071 into /tmp/tmpg8psl4vb/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1145.9636.\n",
      "print_rmse\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-21-15:58:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpg8psl4vb/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-05-21-15:58:21\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 109.036476, global_step = 6071, loss = 12967.553\n",
      "RMSE on dataset = 10.442052841186523\n"
     ]
    }
   ],
   "source": [
    "# TODO: Copy your LinearRegressor estimator and replace with DNNRegressor. \n",
    "# Remember to add a list of hidden units i.e. [32, 8, 2]\n",
    "\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "## DNN Regressorを今回は利用する。\n",
    "model = tf.estimator.DNNRegressor(feature_columns = feature_columns,\n",
    "                                  hidden_units = [32, 8, 2],\n",
    "                                    activation_fn = tf.nn.relu,\n",
    "                                    dropout = 0.2,\n",
    "                                    optimizer=\"Adam\"\n",
    "                                    )\n",
    "\n",
    "print(type(df_train))\n",
    "\n",
    "model.train(make_train_input_fn(df_train, 100))\n",
    "\n",
    "print(\"print_rmse\\n\")\n",
    "print_rmse(model, df_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not beating our benchmark with either model ... what's up?  Well, we may be using TensorFlow for Machine Learning, but we are not yet using it well.  That's what the rest of this course is about!\n",
    "\n",
    "But, for the record, let's say we had to choose between the two models. We'd choose the one with the lower validation error. Finally, we'd measure the RMSE on the test data with this chosen model.\n",
    "\n",
    "\n",
    "どちらのモデルでもベンチマークを打ち負かしていない...どうしたの？ 機械学習にTensorFlowを使用している可能性がありますが、まだ十分に使用していません。 それがこのコースの残りの部分です。\n",
    "\n",
    "ただし、記録のために、2つのモデルから選択する必要があったとします。 検証エラーの少ない方を選択します。 最後に、この選択したモデルを使用して、テストデータのRMSEを測定します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Benchmark dataset </h2>\n",
    "\n",
    "Let's do this on the benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1 = train 2 = valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  EXTRACT(DAYOFWEEK FROM pickup_datetime) * 1.0 AS dayofweek,\n",
    "  EXTRACT(HOUR FROM pickup_datetime) * 1.0 AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count * 1.0 AS passengers,\n",
    "  CONCAT(CAST(pickup_datetime AS STRING), CAST(pickup_longitude AS STRING), CAST(pickup_latitude AS STRING), CAST(dropoff_latitude AS STRING), CAST(dropoff_longitude AS STRING)) AS key\n",
    "FROM\n",
    "  `nyc-tlc.yellow.trips`\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)), 4)) < 2\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)), 4)) = {1}\".format(base_query, phase)\n",
    "  else:\n",
    "    query = \"{0} AND ABS(MOD(FARM_FINGERPRINT(CAST(pickup_datetime AS STRING)), {1})) = {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "df = bigquery.Client().query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare_amount    float64\n",
      "dayofweek      float64\n",
      "hourofday      float64\n",
      "pickuplon      float64\n",
      "pickuplat      float64\n",
      "dropofflon     float64\n",
      "dropofflat     float64\n",
      "passengers     float64\n",
      "key             object\n",
      "dtype: object\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-05-21-16:06:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpg8psl4vb/model.ckpt-6071\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Cast string to float is not supported\n\t [[Node: dnn/input_from_feature_columns/input_layer/key/ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/key/ExpandDims)]]\n\nCaused by op 'dnn/input_from_feature_columns/input_layer/key/ToFloat', defined at:\n  File \"/usr/local/envs/py3env/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/envs/py3env/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-81-c5c04ffae3b1>\", line 2, in <module>\n    print_rmse(model, df)\n  File \"<ipython-input-62-a1fce65954e2>\", line 2, in print_rmse\n    metrics = model.evaluate(input_fn = make_eval_input_fn(df))# dfには、df_validが渡されている\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 425, in evaluate\n    name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1087, in _evaluate_model\n    features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 831, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 494, in _model_fn\n    config=config)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 183, in _dnn_model_fn\n    logits = logit_fn(features=features, mode=mode)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 91, in dnn_logit_fn\n    features=features, feature_columns=feature_columns)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 277, in input_layer\n    trainable, cols_to_vars)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 202, in _internal_input_layer\n    trainable=trainable)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 2297, in _get_dense_tensor\n    return inputs.get(self)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 2100, in get\n    transformed = column._transform_feature(self)  # pylint: disable=protected-access\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 2272, in _transform_feature\n    return math_ops.to_float(input_tensor)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 841, in to_float\n    return cast(x, dtypes.float32, name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1525, in cast\n    \"Cast\", x=x, DstT=DstT, name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nUnimplementedError (see above for traceback): Cast string to float is not supported\n\t [[Node: dnn/input_from_feature_columns/input_layer/key/ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/key/ExpandDims)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Cast string to float is not supported\n\t [[Node: dnn/input_from_feature_columns/input_layer/key/ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/key/ExpandDims)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-c5c04ffae3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-a1fce65954e2>\u001b[0m in \u001b[0;36mprint_rmse\u001b[0;34m(model, df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_eval_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# dfには、df_validが渡されている\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RMSE on dataset = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[0;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m           config=self._session_config)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       _write_dict_to_summary(\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    565\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1044\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Cast string to float is not supported\n\t [[Node: dnn/input_from_feature_columns/input_layer/key/ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/key/ExpandDims)]]\n\nCaused by op 'dnn/input_from_feature_columns/input_layer/key/ToFloat', defined at:\n  File \"/usr/local/envs/py3env/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/envs/py3env/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2907, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-81-c5c04ffae3b1>\", line 2, in <module>\n    print_rmse(model, df)\n  File \"<ipython-input-62-a1fce65954e2>\", line 2, in print_rmse\n    metrics = model.evaluate(input_fn = make_eval_input_fn(df))# dfには、df_validが渡されている\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 425, in evaluate\n    name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 1087, in _evaluate_model\n    features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 831, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 494, in _model_fn\n    config=config)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 183, in _dnn_model_fn\n    logits = logit_fn(features=features, mode=mode)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn.py\", line 91, in dnn_logit_fn\n    features=features, feature_columns=feature_columns)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 277, in input_layer\n    trainable, cols_to_vars)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 202, in _internal_input_layer\n    trainable=trainable)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 2297, in _get_dense_tensor\n    return inputs.get(self)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 2100, in get\n    transformed = column._transform_feature(self)  # pylint: disable=protected-access\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\", line 2272, in _transform_feature\n    return math_ops.to_float(input_tensor)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 841, in to_float\n    return cast(x, dtypes.float32, name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 787, in cast\n    x = gen_math_ops.cast(x, base_type, name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1525, in cast\n    \"Cast\", x=x, DstT=DstT, name=name)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nUnimplementedError (see above for traceback): Cast string to float is not supported\n\t [[Node: dnn/input_from_feature_columns/input_layer/key/ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/key/ExpandDims)]]\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print_rmse(model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE on benchmark dataset is <b>9.41</b> (your results will vary because of random seeds).\n",
    "\n",
    "This is not only way more than our original benchmark of 6.00, but it doesn't even beat our distance-based rule's RMSE of 8.02.\n",
    "\n",
    "Fear not -- you have learned how to write a TensorFlow model, but not to do all the things that you will have to do to your ML model performant. We will do this in the next chapters. In this chapter though, we will get our TensorFlow model ready for these improvements.\n",
    "\n",
    "In a software sense, the rest of the labs in this chapter will be about refactoring the code so that we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Simulate the necessary training dataset.\n",
    "<p>\n",
    "Hint (highlight to see):\n",
    "<p style='color:white'>\n",
    "The input features will be r and h and the label will be $\\pi r^2 h$\n",
    "Create random values for r and h and compute V.\n",
    "Your dataset will consist of r, h and V.\n",
    "Then, use a DNN regressor.\n",
    "Make sure to generate enough data.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
